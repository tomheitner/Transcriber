# Whisper Speaker Diarization - First Release

A local implementation of speaker diarization using Whisper for transcription, inspired by the [Xenova/whisper-speaker-diarization](https://huggingface.co/spaces/Xenova/whisper-speaker-diarization) Hugging Face space.

## ğŸš€ Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the system**:
   ```bash
   python diarization.py
   ```

3. **Check results**:
   - Look in the `results/` folder for output files
   - Run `python demo.py` to see what's available

## âœ¨ Features

- **Whisper Transcription**: High-quality speech-to-text using faster-whisper
- **Basic Speaker Separation**: Simple speaker assignment based on segments
- **Timestamp Alignment**: Word-level timestamps for precise timing
- **Visualization**: Generate timeline plots of speaker segments
- **JSON Export**: Save results in structured JSON format
- **Multi-format Support**: Supports WAV, MP3, FLAC, M4A audio files
- **Multi-language Support**: English, Hebrew, and auto-detection

## ğŸ“ Project Structure

```
speaker_diarization_release/
â”œâ”€â”€ diarization.py  # Main script (ready to use)
â”œâ”€â”€ demo.py                        # System overview and demo
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ data/                         # Audio files directory
â”‚   â”œâ”€â”€ EN - Emily and I 2.wav
â”‚   â”œâ”€â”€ HE - Emily and I.wav
â”‚   â””â”€â”€ Hebrew.wav
â””â”€â”€ results/                      # Output directory
    â”œâ”€â”€ transcription_results.json
    â””â”€â”€ transcription_plot.png
```

## ğŸ¯ What's Included

### Working Features:
- âœ… **Transcription with timestamps**
- âœ… **Basic speaker separation**
- âœ… **Visualization**
- âœ… **JSON export**
- âœ… **Multi-language support**

### Sample Output:
- **JSON Results**: Detailed transcription with speaker segments
- **Timeline Plot**: Visual representation of speaker segments
- **Console Output**: Real-time processing information

## ğŸ”§ Usage

### Basic Usage:
```bash
python diarization.py
```

### Demo:
```bash
python demo.py
```

### Programmatic Usage:
```python
from diarization import SimpleSpeakerDiarizationNoAuth

# Initialize
diarizer = SimpleSpeakerDiarizationNoAuth()

# Process audio
results = diarizer.process_audio("path/to/audio.wav", "output_dir")
```

## ğŸ“Š Output Format

### JSON Structure:
```json
{
  "timestamp": "2024-01-01T12:00:00",
  "segments": [
    {
      "speaker": "SPEAKER_00",
      "start": 0.0,
      "end": 5.2,
      "text": "Hello, how are you today?",
      "words": [
        {"word": "Hello", "start": 0.0, "end": 0.5},
        {"word": "how", "start": 0.6, "end": 0.8}
      ]
    }
  ]
}
```

## ğŸµ Supported Audio

- **Formats**: WAV, MP3, FLAC, M4A
- **Languages**: English, Hebrew, and auto-detection
- **Quality**: Works with various audio qualities

## ğŸ› ï¸ Requirements

- Python 3.8+
- FFmpeg (for audio processing)
- CUDA-compatible GPU (optional, for faster processing)

## ğŸ“ˆ Performance

- **CPU Mode**: Works on any machine
- **GPU Mode**: Automatically detected and used if available
- **Memory**: Efficient processing with streaming

## ğŸ”® Future Versions

This release includes the no-authentication version that works immediately. Future versions will include:

- Full speaker diarization with authentication
- Advanced speaker identification
- Batch processing capabilities
- Web interface

## ğŸ“ License

This implementation is for educational and research purposes. Please respect the licenses of the underlying models:
- Whisper: MIT License
- faster-whisper: MIT License

## ğŸ™ Acknowledgments

- [Xenova](https://huggingface.co/spaces/Xenova/whisper-speaker-diarization) for the original Hugging Face space
- [OpenAI](https://openai.com/research/whisper) for the Whisper model
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) for optimized Whisper inference

---

**Ready to use!** ğŸ¤ Just run `python diarization.py` to get started. 